# cinematic-insights

## Exploratory Data Analysis of Movie Production Companies 

### Objective

Conducted an exploratory data analysis on a dataset of global movie production companies to uncover trends in company establishment, geographic distribution, and market concentration. Utilized Python libraries such as Pandas and Seaborn to derive insights and visualize data.

### Table of Contents:

1. Questions to answer
2. Key Skills and Tools Used
3. Scraping data from wikipedia
4. Data preparation and cleaning 
5. Understanding the data
6. Data Explorations
7. Results and Conclusion
8. Data Sources
#
**1. Questions to answer**

- Which country has the most film companies? <br>
- What is the trend of company establishment over the years? <br>
- Where are most film companies headquartered? <br>
- What is the average lifespan of these companies? <br>
# 
**2. Key Skills and Tools Used**

Programming Languages: Python
Skills: Web scraping, data preparation, visualization and analysis.
Libraries: Pandas, BeautifulSoup, Matplotlib and Seaborn.
Data Visualization: Histograms, count plots and bar charts.
#
**3. Scraping data from wikipedia**

This Jupyter Notebook demonstrates the process of scraping data from Wikipedia using the Beautiful Soup library in Python. The notebook covers the following key steps: <br>

**Importing Libraries:** The necessary libraries, including requests and 'BeautifulSoup', are imported to facilitate web scraping. <br>

**Fetching Data:** A specific Wikipedia page is accessed, and its HTML content is retrieved using the 'requests' library. <br>

**Parsing HTML:** Beautiful Soup is used to parse the HTML content, allowing for easy navigation and extraction of relevant data. <br>

**Data Extraction:** Specific elements, such as tables or lists of movie production companies, are identified and extracted from the parsed HTML. <br>

**Data Cleaning:** The extracted data is cleaned and formatted to prepare it for analysis. <br>

**Output:** The final dataset is displayed, providing a structured view of the scraped information.

The notebook: [Uploading scrap.ipynbâ€¦]()



#
**4. Data preparation and cleaning**
#
**5. Understanding the data**
#
**6. Data Explorations**

7. **Results and Conclusion**
